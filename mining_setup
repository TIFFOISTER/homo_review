library(litsearchr) library(tidyverse) library(dplyr) 
library(readr) library(revtools) library(tm) 
library(SnowballCC) library(RColorBrewer) library(ggplot2) 
library(wordcloud) library(biclust) library(cluster) 
library(igraph)  library(fpc)library(Rcampdf)
setwd('~/Review - Homo E/homo_review') 
mendlib <- read_bibliography('mendeleylib/My Collection.ris')
 ## find_duplicates()& screen_duplicates() -- none identified 
mendresult <- screen_topics(mendlib) ## do not understand this, runs for fuckn ages and doesn't do anything
 
library(filesstrings)
#importing mendeley corpus & writing to plain text 
myfiles <- list.files(path = 'pdffiles', pattern = "pdf",  full.names = TRUE)
lapply(myfiles, function(i) system(paste('"C:/Program Files/Git/mingw64/bin/pdftotext.exe"', paste0('"', i, '"')), wait = FALSE) ) 
#loading plain text for mining 
mytexts <- list.files(path = 'pdffiles', pattern = "txt",  full.names = TRUE)
dir.create('texts')   
file.move(files=myfiles, destinations = 'texts')
docs <- VCorpus(DirSource('texts'))  
##processing text
docs <- tm_map(docs,removePunctuation)  
docs <- tm_map(docs, removeNumbers)  
docs <- tm_map(docs, tolower)   
docs <- tm_map(docs, PlainTextDocument)
DocsCopy <- docs 
docs <- tm_map(docs, removeWords, stopwords("english"))   
docs <- tm_map(docs, PlainTextDocument) 
docs <- tm_map(docs, stripWhitespace) 
docs <- tm_map(docs, PlainTextDocument)
## can remove particular words, and state ones want to keep together 
#staging data
dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)  
